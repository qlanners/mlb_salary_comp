library(caTools)
library(neuralnet)
library(randomForest)
library(ggplot2)

library(readr)
library(ggplot2)

"""
We should have five different scripts (1 in python for web scraping, 3 in R for data work, 
and 1 in latex for the paper), all located in five different folders.
This way we can be well structured  and we won't be mixed up with the (very) different tasks: 
1) web scraping 2) data cleaning 3) machine learning 4) econometrics 5) paper.

Down the road, this is the kind of structure that can be pushed to github.

Every folder contains a script and an output. I see outputs in the form of txt documents
for logs and csv documents for the data. Names of folders/scripts/outputs must be thoughtful
and follow a certain logic. The current names are bad.

1- One devoted to web scraping. This is already done but we need to create a folder,
  place the script in it. The ouputs of the script should be placed in that same folder, 
  and renamed appropriately. 

2- One that is devoted to data cleaning and feature engineering only.
  The data cleaning script feeds into the web scraping folder for its data source. This way,  
  if we have to run the scraper again, the data cleaning script automatically 
  uses an updated data set and nothing breaks downstream.

  The output(s) of that script should be in the form of csv's perhaps three, one with all players,
  one with only the vets, and one with only the non vets. All three data sets should have the 
  same exact features, which is to say that the vets/non-vets partion is applied at the very end
  of the script. Any output of that script stays in that folder. 

3- One that is devoted to machine learning only, but more specifically about fitting a model
  on the vets dataset, where the target is ln_real_total_salary. The script will feed 
  in the data cleaning folder for its data source.The output of that script should 
  consist of txt documents that keep track of the performance of the models and different important
  logs and probably some graphs in png format. 
  The ultimate output of that script should be a csv document with predicted salaries, 
  probably in log of the non-vets, along with all the columns, not just the columns used
  in the model. The reason is that in part 4), we will probably use different features.

4- One that is devoted to the econometrics part, which is to explain what drives differences
  between observed salaries and predicted salaris. The script will feed into the machine learning 
  folder for its data source. Outputs should be graphs and text documents that contain,
  latex codes, generated by R, used to generate tables in the paper. Since the paper is written in 
  latex code, I believe we can automate the generation of tables by calling 
  txt documents within the latex sript. Again, we modifications are made upstream, nothing 
  has to be modified downstream, and nothing breaks. We can probably automate the downstream 
  updating with a simple shell script.

5- one latex code for the paper. The code feeds into the machine learning and econometrics 
  folders for graphs and table sources. Output is a pdf.
  
Structure and appropriate folder/document/script names are key. Gotta keep track of 
everything in a meaningful manner, since we might only work on it during our spare time. Gotta
make sure that everything is readable and, more importantly, easily understandable.
"""


salaries <- read_csv("C:/Users/jfran/Dropbox/Research Projects/OpenWar/Data/scraped_data/most recent data/salaries.csv")
batters_bbr_full_TOTs_removed <- read_csv("C:/Users/jfran/Dropbox/Research Projects/OpenWar/Data/scraped_data/most recent data/batters_bbr_full_TOTs_removed.csv")
inflation <- read_csv("C:/Users/jfran/Dropbox/Research Projects/OpenWar/Data/scraped_data/most recent data/inflation.csv")

colnames(batters_bbr_full_TOTs_removed)[1] <- "year"
joined <- merge(batters_bbr_full_TOTs_removed, salaries, by=c('key','year'))

joined$reached_vet <- FALSE

vets <- subset(salaries, status=="Vet")
vet_keys <- vets['key']
vet_keys <- unique(vet_keys)
vet_keys <- unlist(vet_keys)

for (i in 1:dim(joined)[1]) {
  if (joined$key[i] %in% vet_keys) {
    joined$reached_vet[i] <- TRUE
  }
}

joined$total_salary <- as.numeric(gsub('[$,]', '', joined$total_salary))
joined <- subset(joined, !is.na(total_salary))

## cpi enters here
## I changed the way of accounting for cpi by simply using a left join with joined and inflation on year.
##Then create Real_total_salary by multiplying total_salary by cpi
## I also placed it earlier in the code

#for (row in 1:nrow(vets)) {
#  vets$total_salary[row] <- vets$total_salary[row] * subset(inflation, year == vets[row, "year"])$cpi
#}

joined <- merge(joined, inflation, by='year')
joined$real_total_salary <- joined_cpi$total_salary * joined_cpi$cpi

#log salary enters here
#let's keep the real salary column by adding log column instead of replacing it.
#the log transformation should be applied to all subsets, not just vets.
#vets$real_total_salary <- log(vets$real_total_salary)

joined$ln_real_total_salary <- log(joined$real_total_salary)



joined$hits_game <- joined$H / joined$G
joined$hr_game <- joined$HR / joined$G
joined$rbi_game <- joined$RBI / joined$G

##Should maybe write a function that takes care of the data cleaningé
## restricting only to PA >=500 reduces the data set by more than 4000.
## should probably check about reducing it to keep deciles 10 to 100 for instance


joined <- subset(joined, PA > quantile(joined$PA,.1))

## This partionning of joined should be done after the feature engineering is complete.
## We have to make sure all columns are the same in all subsets.


set.seed(123)


results <- data.frame(Test_Type=character(),
                      Variables=character(),
                      ntree=integer(),
                      mtry=integer(),
                      hidden=character(),
                      RMSE=double(),
                      stringsAsFactors=FALSE)





#Can you explain why you take out these columns?
# I think some columns in there should be kept. Here some reasons why I would keep some of them
#age : this captures experience level. Although when predicting on the non-vets, we
        # have to be careful since the age ranges probably do not overlap
#status : it will be an important regressor after
#lux_tax : we can use this as an indicator of rich vs poor teams. Let's be careful if it
          #only identify the Yankees. Still need to keep track of extra-rich vs rich vs poor

""" 
*** Again, all the feature engineering you are doing on Vets, do it on Joined and after, 
*** you can partition joined.


vets <- subset(vets, select = -c(key, Lg, Salary, Tm2, Tm3, age, status, base_salary, signing_bonus, incentives, adjusted_salary, payroll_perc, active, lux_tax, team, reached_vet))

"""


## Can you explain this part?

"""
teams <- unique(vets$Tm)

for (row in 1:nrow(vets)) {
  vets[row, 'Tm'] <- which(teams == vets[row, 'Tm'])
}

for (row in 1:nrow(vets)) {
  vets[row, 'Pos'] <- gsub("\\*","",vets[row, 'Pos'])
  vets[row, 'Pos'] <- gsub("/","",vets[row, 'Pos'])
  vets[row, 'Pos'] <- substring(vets[row, 'Pos'], 1, 1)
}

vets <- vets[!is.na(vets$Pos),]

positions <- unique(vets$Pos)

for (row in 1:nrow(vets)) {
  vets[row, 'Pos'] <- which(positions == vets[row, 'Pos'])
}
"""

### Are you creating dummy variables? There might be better ways to do it. Check out packages
### like fastDummies for instance

vets['mvp'] <- 0
vets['roy'] <- 0
vets['as'] <- 0
vets['gg'] <- 0
vets['ss'] <- 0

for (row in 1:nrow(vets)) {
  if (grepl('MVP',vets[row, 'Awards'])) {
    vets[row,'mvp'] <- 1
  }
  if (grepl('RoY',vets[row, 'Awards'])) {
    vets[row,'roy'] <- 1
  }
  if (grepl('AS',vets[row, 'Awards'])) {
    vets[row,'as'] <- 1
  }
  if (grepl('GG',vets[row, 'Awards'])) {
    vets[row,'gg'] <- 1
  }
  if (grepl('SS',vets[row, 'Awards'])) {
    vets[row,'ss'] <- 1
  }  
}



vets <- subset(vets, select = -c(Awards))



colnames(vets)[colnames(vets)=='OPS+'] <- "OPS_plus"
colnames(vets)[colnames(vets)=='2B'] <- "double"
colnames(vets)[colnames(vets)=='3B'] <- "triple"
colnames(vets)[colnames(vets)=='waaWL%'] <- "wl_av_team"
colnames(vets)[colnames(vets)=='162WL%'] <- "wl_av_team_season"

## Partionning should go here.

#pre_arb <- subset(joined, status=='Pre-Arb')
#arb_1 <- subset(joined, status=='Arb 1')
#arb_2 <- subset(joined, status=='Arb 2')
#arb_3 <- subset(joined, status=='Arb 3')
#vets <- subset(joined, status=='Vet')

# I Stopped reading the script here.

vets <- sapply( vets, as.numeric)
vets <- as.data.frame(vets)
mins = apply(vets,2,min)
maxs = apply(vets,2,max)
scaled_vets <- scale(vets, center=mins, scale=maxs-mins)
scaled_vets <- as.data.frame(scaled_vets)

sample = sample.split(scaled_vets$total_salary , SplitRatio = 0.8)
train = subset(scaled_vets, sample == TRUE)
test = subset(scaled_vets, sample == FALSE)

v1 <- c('year','Age','H','HR','RBI','BA','OPS_plus','WAR','as')
nn1 = list("NN",v1,c(5,3))
nn2 = list("NN",v1,c(10,6,3))
print(c(5,3))
print(typeof(c(5,3)))
rf1 = list("RF","all",500,max(floor(ncol(vets)/3), 1))
rf1.1 = list("RF","all",500,max(floor(ncol(vets)/4), 1))
rf2 = list("RF","all",500,max(floor(ncol(vets)/2), 1))
tlist = list(rf2)
test_number = 1
for (t in tlist) {
  if (t[2] == "all") {
    f <- "total_salary ~ ."
    test_input <- test
  } else {
    f <- as.formula(paste("total_salary ~", paste(unlist(t[2], use.names = FALSE), collapse = " + ")))
    test_input <- test[unlist(t[2], use.names = FALSE)]
  }
  if (t[1] == "NN") {
    model <- neuralnet(f, data = train, hidden = c(unlist(t[3])), stepmax=1e6, linear.output = TRUE)
    predicted <- compute(model,test_input)
    true.predictions <- predicted$net.result * (max(vets$total_salary)-min(vets$total_salary))+min(vets$total_salary)
  } else if (t[1] == "RF") {
    print('hi2')
    print(t[3])
    print(unlist(t[4]))
    model <- randomForest(as.formula(f), data=train, ntree = unlist(t[3]), mtry = unlist(t[4]), proximity=TRUE)
    predicted <- predict(model,test_input,predict.all = TRUE)
    true.predictions <- predicted$aggregate * (max(vets$total_salary)-min(vets$total_salary))+min(vets$total_salary)
  }
  test.r <- (test$total_salary) * (max(vets$total_salary)-min(vets$total_salary))+min(vets$total_salary)
  RMSE <- sqrt(sum((test.r - true.predictions)^2)/nrow(test))
  if (t[1] == "NN") {
    results[test_number,] = list(t[1],paste("(",toString(unlist(t[2], use.names = FALSE)),")", sep = ""),NA,NA,paste("(",toString(unlist(t[3], use.names = FALSE)),")", sep = ""),RMSE)
  } else if (t[1] == "RF") {
    results[test_number,] = list(t[1],paste("(",toString(unlist(t[2], use.names = FALSE)),")", sep = ""),t[3],t[4],NA,RMSE)
  }
  
  test_number <- test_number + 1
  error.df <- data.frame(test.r,true.predictions)
  print(ggplot(error.df, aes(x=test.r,y=true.predictions)) + geom_point() + stat_smooth())
  
  res <- true.predictions - test.r
  res.df <- data.frame(res)
  
  print(ggplot(res.df, aes(x=res)) + geom_histogram())
}

print(results)

# scaled_pre_arb_vet <- scaled_pre_arb_vet[!is.na(scaled_pre_arb_vet),]
# 
# scaled_pre_arb_vet <- as.data.frame(scaled_pre_arb_vet)
# predicted <- predict(model,scaled_pre_arb_vet,predict.all = TRUE)
# 
# any(is.na(scaled_pre_arb_vet))
# any(is.na(train))
# 
# print(predicted$aggregate)
# true.predictions <- predicted$aggregate * (max(scaled_pre_arb_vet$total_salary)-min(scaled_pre_arb_vet$total_salary))+min(scaled_pre_arb_vet$total_salary)
# test.r <- (scaled_pre_arb_vet$total_salary) * (max(scaled_pre_arb_vet$total_salary)-min(scaled_pre_arb_vet$total_salary))+min(scaled_pre_arb_vet$total_salary)
# 
# true.predictions
# true.predictions <- exp(true.predictions)
# test.r <- exp(test.r)
# 
# dif <- true.predictions - test.r
# 
# print(true.predictions)
# 
# print(dif)
# 
# linmodel <- lm(dif~., data = scaled_pre_arb_vet)
# summary(linmodel)
